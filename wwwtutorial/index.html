<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="WWW 2025 Tutorial: Rethink Deep Learning with Invariance in Data Representation">
  <meta name="keywords" content="WWW, Tutorial, Deep Learning, Invariance">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>WWW 2025 Tutorial: Rethink Deep Learning with Invariance in Data Representation</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">
              <span style="font-size: 80%">WWW 2025 Tutorial:</span><br />
              Rethink Deep Learning with<br />Invariance in Data Representation
            </h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <table>
            <tr>
                <!-- <th scope="row">TR-7</th> -->
                <td width="25%" style="text-align: center; padding: 3px"><img width="150px" height="150px" src="static/imgs/shurenqi.jpg"></td>
                <td width="25%" style="text-align: center; padding: 3px"><img width="150px" height="150px" src="static/imgs/feiwang.jpg"></td>
                <td width="25%" style="text-align: center; padding: 3px"><img width="150px" height="150px" src="static/imgs/tieyongzeng.jpg"></td>
                <td width="25%" style="text-align: center; padding: 3px"><img width="150px" height="150px" src="static/imgs/fengleifan.jpg"></td>
            </tr>
              <tr>
                <!-- <th scope="row">TR-7</th> -->
                <td width="25%" style="text-align: center"><a href="https://shurenqi.github.io/" style="border-radius: 50%">Shuren Qi</a><sup>1</sup>,</td>
                <td width="25%" style="text-align: center"><a href="https://wcm-wanglab.github.io/" style="border-radius: 50%">Fei Wang</a><sup>2</sup>,</td>
                <td width="25%" style="text-align: center"><a href="https://www.math.cuhk.edu.hk/~zeng/" style="border-radius: 50%">Tieyong Zeng</a><sup>1</sup>,</td>
                <td width="25%" style="text-align: center"><a href="https://fengleifan.github.io/Feng-Lei.Fan.github.io/about.html" style="border-radius: 50%">Fenglei Fan</a><sup>3</sup></td>
              </tr>
            </table>
            </span>
          </div>
          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>1</sup>The Chinese University of Hong Kong,</span>
            <span class="author-block"><sup>2</sup>Cornell University,</span>
			<span class="author-block"><sup>3</sup>City University of Hong Kong</span>
          </div>
          <br />
          <div class="is-size-5 publication-authors">
            <b>Date: 13:30 - 16:30, Tuesday, April 29, 2025</b>
          </div>
		  <div class="is-size-5 publication-authors">
            <b>Location: Room C3.4, ICC Sydney, Australia</b>
          </div>
          

          <div class="is-size-5 publication-authors">
            <!--
            Zoom link available on <a href="https://underline.io/events/395/sessions?eventSessionId=15330&searchGroup=lecture" target="_blank">Underline</a>
            -->
            <!--
			Visit <a target="_blank" href="https://us06web.zoom.us/rec/play/6fqU9YDLoFtWqpk8w8I7oFrszHKW6JkbPVGgHsdPBxa69ecgCxbmfP33asLU3DJ74q5BXqDGR2ycOTFk.93teqylfi_uiViNK?canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fus06web.zoom.us%2Frec%2Fshare%2FNrYheXPtE5zOlbogmdBg653RIu7RBO1uAsYH2CZt_hacD1jOHksRahGlERHc_Ybs.KGX1cRVtJBQtJf0o">this link</a>
            for the Zoom recording of the tutorial
          </div>
		  -->
          <!--<div class="is-size-6 publication-authors">
            For those who have not registered to ACL: we will release video recordings after the tutorial
          </div>
          <br />-->
		  <!--
          <div class="is-size-5 publication-authors">
            QnA: <a href="https://tinyurl.com/retrieval-lm-tutorial" target="_blank"><b>tinyurl.com/retrieval-lm-tutorial</b></a>
          </div>
		  -->
        </div>
      </div>
    </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
             Integrating invariance into data representations is a principled 
			 design in intelligent systems and web applications. Representations
			 play a fundamental role, where systems and applications are both
			 built on meaningful representations of digital inputs (rather than
			 the raw data). In fact, the proper design/learning of such representations 
			 relies on priors w.r.t. the task of interest. Here, the concept
			 of symmetry from the Erlangen Program may be the most fruitful
			 prior — informally, a symmetry of a system is a transformation
			 that leaves a certain property of the system invariant. Symmetry
			 priors are ubiquitous, e.g., translation as a symmetry of the object
			 classification, where object category is invariant under translation.
          </p>
          <p>
            The quest for invariance is as old as pattern recognition and
			data mining itself. Invariant design has been the cornerstone of
			various representations in the era before deep learning, such as the SIFT.
			As we enter the early era of deep learning, the invariance principle is largely 
			ignored and replaced by a data-driven paradigm, such as the CNN.
			However, this neglect did not last long before
			they encountered bottlenecks regarding robustness, interpretability,
			efficiency, and so on. The invariance principle has returned in the era
			of rethinking deep learning, forming a new field known as Geometric
			Deep Learning (GDL).
          </p>
		  <p>
            In this tutorial, we will give a historical perspective of the 
			invariance in data representations. More importantly, we will identify
			those research dilemmas, promising works, future directions, and
			web applications.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Schedule</h2>
        <p>
          Materials:
		  <a href="./materials/fullslides.pdf" target="_blank">[Full Slides]</a>
		  <a href="./materials/proposal.pdf" target="_blank">[Tutorial Proposal]</a>
		  <a href="https://www.dropbox.com/scl/fo/yj261r2tefsatajs83ju5/ACIcJmjCZXqhFhvu2pLvu5w?dl=0&e=1&preview=WWW+Tutorial+Video+Teaser+by+ShurenQi.mp4&rlkey=noxe7toqy7konflqq9kbcy05r&st=q9241kft" target="_blank">[Video Teaser]</a> 
        </p>

        <div class="content has-text-justified">

          <style type="text/css">
          .tg  {border-collapse:collapse;border-spacing:0;}
          .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
            overflow:hidden;padding:10px 5px;word-break:normal;}
          .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
            font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
          .tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
          .tg .tg-0lax{text-align:left;vertical-align:top}
          </style>
          <table class="tg">
          <thead>
            <tr>
              <th class="tg-0pky">Time</th>
              <th class="tg-0lax">Part</th>
              <th class="tg-0lax">Slides</th>
            </tr>
          
          <tbody>
			<tr>
              <td class="tg-0lax">5 min</td>
              <td class="tg-0lax">Part 0: Opening remarks</td>
              <td class="tg-0lax"><a href="./materials/0.pdf" target='_blank'>[Part 0 Slides]</a></td>
            </tr>
			
            <tr>
              <td class="tg-0lax">20 min</td>
              <td class="tg-0lax">Part 1: Background and challenges</td>
              <td class="tg-0lax"><a href="./materials/1.pdf" target='_blank'>[Part 1 Slides]</a></td>
            </tr>
			
			<tr>
              <td class="tg-0lax">20 min</td>
              <td class="tg-0lax">Part 2: Preliminaries of invariance</td>
              <td class="tg-0lax"><a href="./materials/2.pdf" target='_blank'>[Part 2 Slides]</a></td>
            </tr>
			
			<tr>
              <td class="tg-0lax">10 min</td>
              <td class="tg-0lax">Q&A / Break</td>
              <td class="tg-0lax"> </td>
            </tr>
			
			<tr>
              <td class="tg-0lax">30 min</td>
              <td class="tg-0lax">Part 3: Invariance in the era before deep learning</td>
              <td class="tg-0lax"><a href="./materials/3.pdf" target='_blank'>[Part 3 Slides]</a></td>
            </tr>
			
			<tr>
              <td class="tg-0lax">10 min</td>
              <td class="tg-0lax">Part 4: Invariance in the early era of deep learning</td>
              <td class="tg-0lax"><a href="./materials/4.pdf" target='_blank'>[Part 4 Slides]</a></td>
            </tr>
			
			<tr>
              <td class="tg-0lax">30 min</td>
              <td class="tg-0lax">Q&A / Coffee Break</td>
              <td class="tg-0lax"> </td>
            </tr>
			
			<tr>
              <td class="tg-0lax">50 min</td>
              <td class="tg-0lax">Part 5: Invariance in the era of rethinking deep learning</td>
              <td class="tg-0lax"><a href="./materials/5.pdf" target='_blank'>[Part 5 Slides]</a></td>
            </tr>
			
			<tr>
              <td class="tg-0lax">20 min</td>
              <td class="tg-0lax">Part 6: Conclusions and discussions</td>
              <td class="tg-0lax"><a href="./materials/6.pdf" target='_blank'>[Part 6 Slides]</a></td>
            </tr>
			
			<tr>
              <td class="tg-0lax">10 min</td>
              <td class="tg-0lax">Q&A</td>
              <td class="tg-0lax"> </td>
            </tr>
          
		  </thead> 
          </tbody>
          </table>
        </div>
      </div>
    </div>

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Reading List</h2>

        <p><b>Bold papers</b> are the focus of the reading.</p>

        <br />
        
        
        <h3 class="title is-5">Part 1: Background and challenges</h3>

        <ol>
          <li>C Buckner. Understanding adversarial examples requires a theory of artefacts for deep learning. Nature Machine Intelligence, 2020.</li>
          <li>X Li, C Cao, Y Shi, et al. A survey of data-driven and knowledge-aware explainable AI. TKDE, 2020.</li>
		  <li>E Strubell, A Ganesh, A McCallum, et al. Energy and policy considerations deep learning research. AAAI, 2020.</li>
		  <li><b>H Liu, M Chaudhary, H Wang. Towards trustworthy and aligned machine learning: A data-centric survey with causality perspectives. arXiv preprint arXiv:2307.16851, 2023.</b></li>
		  <li>F Klein. A comparative review of recent researches in geometry. Bulletin of the American Mathematical Society, 1893.</li>
		  <li>H Weyl. Symmetry. Princeton University Press, 2015.</li>
		  <li>Y LeCun, Y Bengio, G Hinton. Deep learning. Nature, 2015.</li>
		  <li>Y Bengio, A Courville, P Vincent. Representation learning: A review and new perspectives. TPAMI, 2013.</li>
        </ol>
        
        <br />
		
		<h3 class="title is-5">Part 2: Preliminaries of invariance</h3>

        <ol>
		  <li><b>K Lenc, A Vedaldi. Understanding image representations by measuring their equivariance and equivalence. CVPR, 2015.</b></li>
		  <li><b>MM Bronstein, J Bruna, Y LeCun, et al. Geometric deep learning: going beyond euclidean data. IEEE Signal Processing Magazine, 2017.</b></li>
        </ol>
        
        <br />
		
		<h3 class="title is-5">Part 3: Invariance in the era before deep learning</h3>

        <ol>
		  <li>K Mikolajczyk, C Schmid. A performance evaluation of local descriptors. TPAMI, 2005.</li>
		  <li><b>J. Flusser, B. Zitova, T. Suk. Moments and Moment Invariants in Pattern Recognition. John Wiley & Sons, 2009.</b></li>
		  <li>MK Hu. Visual pattern recognition by moment invariants. TIT, 1962.</li>
		  <li>A Khotanzad, YH Hong. Invariant image recognition by Zernike moments. TPAMI, 1990.</li>
		  <li><b>S Qi, Y Zhang, C Wang, et al. A survey of orthogonal moments for image representation: Theory, implementation, and evaluation. ACM Computing Surveys, 2023.</b></li>
		  <li>S Qi, Y Zhang, C Wang, et al. Representing noisy image without denoising. TPAMI, 2024.</li>
		  <li>AV Oppenheim, JS Lim. The importance of phase in signals. Proceedings of the IEEE, 1981.</li>
		  <li><b>S Mallat. A Wavelet Tour of Signal Processing. Elsevier, 1999.</b></li>
		  <li>DG Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 2004.</li>
		  <li><b>T Lindeberg. Scale-space Theory in Computer Vision. Springer Science & Business Media, 1993.</b></li>
		  <li><b>A Iscen, G Tolias, PH Gosselin, et al. A comparison of dense region detectors for image search and fine-grained classification. TIP, 2015.</b></li>
		  <li>E Tola, V Lepetit, P Fua. Daisy: An efficient dense descriptor applied to wide-baseline stereo. TPAMI, 2009.</li>
		  <li><b>S Qi, Y Zhang, C Wang, et al. A principled design of image representation: Towards forensic tasks. TPAMI, 2023.</b></li>
        </ol>
        
        <br />
		
		<h3 class="title is-5">Part 4: Invariance in the early era of deep learning</h3>

        <ol>
		  <li>A Krizhevsky, I Sutskever, GE Hinton. ImageNet classification with deep convolutional neural networks. NIPS , 2012.</li>
		  <li>F Rosenblatt. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological Review, 1958.</li>
		  <li><b>K Fukushima, S Miyake. Neocognitron: A new algorithm for pattern recognition tolerant of deformations and shifts in position. Pattern Recognition, 1982.</b></li>
		  <li>Y LeCun, B Boser, J Denker, et al. Handwritten digit recognition with a back-propagation network. NIPS, 1989.</li>
        </ol>
        
        <br />
		
		<h3 class="title is-5">Part 5: Invariance in the era of rethinking deep learning</h3>

        <ol>
		  <li><b>MM Bronstein, J Bruna, T Cohen, et al. Geometric deep learning: Grids, groups, graphs, geodesics, and gauges. arXiv preprint arXiv:2104.13478, 2021.</b></li>
		  <li>J Bruna, S Mallat. Invariant scattering convolution networks. TPAMI, 2013.</li>
		  <li><b>J Bruna, S Mallat. Rotation, scaling and deformation invariant scattering for texture discrimination. CVPR, 2013.</b></li>
		  <li><b>T Cohen, M Welling. Group equivariant convolutional networks. ICML, 2018.</b></li>
		  <li>M Weiler, FA Hamprecht, M Storath. Learning steerable filters for rotation equivariant CNNs. CVPR, 2018. </li>
		  <li>EJ Bekkers. B-spline CNNs on lie groups. ICLR, 2020.</li>
		  <li><b>M Zaheer, S Kottur, S Ravanbakhsh. Deep sets. NIPS, 2017.</b></li>
		  <li>CR Qi, H Su, K Mo, et al. PointNet: Deep learning on point sets for 3D classification and segmentation. CVPR, 2017. </li>
		  <li>TN Kipf, M Welling. Semi-supervised classification with graph convolutional networks. ICLR, 2017. </li>
		  <li>P Veličković, G Cucurull, A Casanova, et al. Graph attention networks. ICLR, 2018.</li>
		  <li><b>J Gilmer, SS Schoenholz, PF Riley, et al. Neural message passing for quantum chemistry. ICML, 2017.</b></li>
		  <li>CK Joshi. https://thegradient.pub/transformers-are-graph-neural-networks/</li>
		  <li><b>S Qi, Y Zhang, C Wang, et al. Transparent vision: A theory of hierarchical invariant representations. ICCV, 2025.</b></li>
		  <li>T Wang, Y Zhang, S Qi, et al. Security and privacy on generative data in AIGC: A survey. ACM Computing Surveys, 2024.</li>
		  <li><b>Y Zhang, Y Sun, S Qi, et al. Atkscopes: Multiresolution adversarial perturbation as a unified attack on perceptual hashing and beyond. USENIX Security, 2025.</b></li>
        </ol>
        
        <br />

        
      </div>
    </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{www25-invariance-tutorial,
  title={Rethink Deep Learning with Invariance in Data Representation},
  author={Qi, Shuren and Wang, Fei and Zeng, Tieyong and Fan, Fenglei},
  booktitle={In Companion Proceedings of the ACM Web Conference},
  year={2025}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
  <center> <a href="https://info.flagcounter.com/oSWA"><img src="https://s11.flagcounter.com/mini/oSWA/bg_FFFFFF/txt_000000/border_C2C2C2/flags_0/" alt="Flag Counter" border="0"></a></center>


</footer>

</body>
</html>
